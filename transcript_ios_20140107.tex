%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 20140107 - Introduction to Operating Systems VO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%fancyhdr
\lhead{IOS VO} 
\rhead{2014-01-07}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\par{
	\noindent\underline{Recapitulation: memory of concurrent processes}
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
			\tikzset{memory_entry/.style = {draw, minimum width = 3cm}}
			
			\node[memory_entry, minimum height = 1.5cm] at (0, 0) (code_procA) {\footnotesize{Code}};
			\node[memory_entry, minimum height = 1cm, above = -0.015 of code_procA] (globals_procA) {\footnotesize{Globals / Strings}};
			\node[memory_entry, minimum height = 3.5cm, above = -0.015 of globals_procA] (stack_heap_procA) {};
			\draw[->, >=stealth] (stack_heap_procA.south) -- ++(0, 0.5) node[right] {\footnotesize{Heap}};
			\draw[->, >=stealth] (stack_heap_procA.north) -- ++(0, -0.5) node[right] {\footnotesize{Stack}};
			\draw[<-, >=stealth] (code_procA.east) -- ++(0.5, 0) node[right] {\footnotesize{PC}};
			\node[left = 0 of code_procA.south west] {\footnotesize{0}};
			\node[left = 0 of stack_heap_procA.north west] {\footnotesize{max}};
			\node[draw, minimum height = 0.5, minimum width = 0.5, above right = 0.5 of stack_heap_procA.south west] (heap_element) {};
			\node[below right = 0.5 of code_procA.north west] (code_invis) {};
			\node[left = 0.5 of globals_procA.south west] (code_invis_way1) {};
			\node[left = 0.5 of globals_procA.north west] (code_invis_way2) {};
			\draw[->, >=stealth] (code_invis) .. controls (code_invis_way1) and (code_invis_way2) .. (heap_element.west);
			\node[below = 0 of code_procA.south] {\footnotesize{process A}};

			\node[memory_entry, minimum height = 1.5cm, right = 4 of code_procA] (code_procB) {\footnotesize{Code}};
			\node[memory_entry, minimum height = 1cm, above = -0.015 of code_procB] (globals_procB) {\footnotesize{Globals / Strings}};
			\node[memory_entry, minimum height = 3.5cm, above = -0.015 of globals_procB] (stack_heap_procB) {};
			\draw[->, >=stealth] (stack_heap_procB.south) -- ++(0, 0.5) node[right] {\footnotesize{Heap}};
			\draw[->, >=stealth] (stack_heap_procB.north) -- ++(0, -0.5) node[right] {\footnotesize{Stack}};
			\node[left = 0 of code_procB.south west] {\footnotesize{0}};
			\node[left = 0 of stack_heap_procB.north west] {\footnotesize{max}};
			\node[below = 0 of code_procB.south] {\footnotesize{process B}};

			\draw (stack_heap_procA.east) ++(2, 0) -- ++(0, -2);
			\draw (stack_heap_procA.east) ++(2.1, 0) -- ++(0, -2);
		\end{tikzpicture}
		\caption{Concurrent processes and their memory layout}
		\label{fig:concurrprocsmemlayout}
	\end{figure}
}

\par{
	\noindent
	Fundamental reason for parallelism/concurrency (parallelism $\not=$ concurrency!): \newline
	Because the world we are living in consists of lots of parallel processes $\Rightarrow$ real world picture; it is not about convenience! It is also about correctness proofs $\Rightarrow$ to prove that one big program is correct is much more difficult to show than multiple concurrent programs. \newline
	The ultimate prerequisite to accomplish this: each process has to think he owns the whole machine \& memory.
}

\par{
	\noindent
	Physical memory is:
	\parskip0pt\begin{enumerate}
		\item{a set of addresses}
		\item{content of these }
	\end{enumerate}
	Virtual memory is:
	\parskip0pt\begin{enumerate}
		\item{a set of addresses}
	\end{enumerate}
	Paging: Split virtual and physical memory into 4kB pages (of addresses).
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
			\tikzset{memory_entry/.style = {draw, minimum width = 3cm, minimum height = 0.5cm}}
			\tikzset{page_table_entry/.style = {draw, minimum width = 2cm, minimum height = 0.5cm}}

			\node[memory_entry] at (0, 0) (virtmem_entry1) {};
			\node[memory_entry, above = -0.015 of virtmem_entry1] (virtmem_entry2) {};
			\node[draw, minimum width = 3cm, minimum height = 3cm, above = -0.015 of virtmem_entry2] (virtmem_dots) {\footnotesize{\ldots}};
			\node[memory_entry, above = -0.015 of virtmem_dots] (virtmem_entry3) {};
			\node[memory_entry, above = -0.015 of virtmem_entry3] (virtmem_entry4) {};
			\node[below = 0 of virtmem_entry1] (virtmem_t) {\footnotesize{virtual memory}};
			\draw[<-, >=stealth] (virtmem_entry1.north west) -- ++(-0.5, 0) node[left] {\footnotesize{4kB}};
			\draw[<-, >=stealth] (virtmem_entry2.north west) -- ++(-0.5, 0) node[left] {\footnotesize{8kB}};

			\node[page_table_entry, right = 2 of virtmem_entry2] (pt_entry1) {};
			\node[page_table_entry, above = -0.015 of pt_entry1] (pt_entry2) {};
			\node[draw, minimum width = 2cm, minimum height = 1cm, above = -0.015 of pt_entry2] (pt_dots) {\footnotesize{\ldots}};
			\node[page_table_entry, above = -0.015 of pt_dots] (pt_entry3) {};
			\node[page_table_entry, above = -0.015 of pt_entry3] (pt_entry4) {};
			\node[below = 0 of pt_entry1] (pt_t) {\footnotesize{page table}};

			\node[memory_entry, right = 6 of virtmem_entry1] (physmem_entry1) {};
			\node[memory_entry, above = -0.015 of physmem_entry1] (physmem_entry2) {};
			\node[draw, minimum width = 3cm, minimum height = 3cm, above = -0.015 of physmem_entry2] (physmem_dots) {\footnotesize{\ldots}};
			\node[memory_entry, above = -0.015 of physmem_dots] (physmem_entry3) {};
			\node[memory_entry, above = -0.015 of physmem_entry3] (physmem_entry4) {};
			\node[below = 0 of physmem_entry1] (physmem_t) {\footnotesize{physical memory}};
			\draw[<-, >=stealth] (physmem_entry1.north east) -- ++(0.5, 0) node[right] {\footnotesize{4kB}};
			\draw[<-, >=stealth] (physmem_entry2.north east) -- ++(0.5, 0) node[right] {\footnotesize{8kB}};

			\foreach \i in {1, 2} {
				\node[right = 0.5 of virtmem_entry\i] (virtmem_entry\i_invis_right) {};
				\node[left = 0.5 of pt_entry\i] (pt_entry\i_invis_left) {};
				\draw[->, >=stealth] (virtmem_entry\i.east) .. controls (virtmem_entry\i_invis_right) and (pt_entry\i_invis_left) .. (pt_entry\i.west);
			}

			\node[right = 0.5 of pt_entry1] (pt_entry1_invis_right) {};
			\node[left = 0.5 of physmem_entry3] (physmem_entry3_invis_left) {};
			\draw[->, >=stealth] (pt_entry1.east) .. controls (pt_entry1_invis_right) and (physmem_entry3_invis_left) .. (physmem_entry3.west);

			\node[right = 0.5 of pt_entry2] (pt_entry2_invis_right) {};
			\node[left = 0.5 of physmem_entry1] (physmem_entry1_invis_left) {};
			\draw[->, >=stealth] (pt_entry2.east) .. controls (pt_entry2_invis_right) and (physmem_entry1_invis_left) .. (physmem_entry1.west);
		\end{tikzpicture}
		\caption{Mapping virtual $\leftrightarrow$ physical memory}
		\label{fig:mappingvirtphysmem}
	\end{figure}
	\par{
		\noindent
		Page tables are process-local (each process has its own). On process creation the page table is empty (there is are no mappings of any virtual to any physical addresses). Page frames are organised by a free list $\Rightarrow$ $O(1)$ access and no additional space needed (no overhead) because the pointers of the free list can be stored in the free page frames.
	}
	\par{
		\noindent\newline When a page fault occurs:
		\parskip0pt\begin{itemize}
			\item{create mapping $\rightarrow$ resolved by MMU $\rightarrow$ good performance needed because there are lots of requests $\rightarrow$ page table is cached into translation lookaside buffer (TLB) $\rightarrow$ is in RAM (not everything is split into 4kB chunks).}
			\item{if it is in the code segment: load 4kB from disk into frame.}
		\end{itemize}
	}
	\par{
		\noindent
		CR3 register in MMU points to the currently used page table and is used when a process switch is done:
		\parskip0pt\begin{itemize}
			\item{set program counter}
			\item{restore state of new process (registers, et cetera)}
		\end{itemize}
	}
	\par{
		\noindent\underline{Translation lookaside buffer (TLB):}
		\par{
			\noindent
			Is a fully-associative memory: entry is split into two columns: content \& address (see Figure~\ref{fig:tlborg}). Has about 20 entries for $\frac{2^{32}}{4kB (\text{page size})} = \frac{2^{32}}{2^{12}} = 2^{20}$ page table entries. Thus, there is no one-to-one mapping because this would lead to as much virtual as physical addresses $\Rightarrow$ no external fragmentation because of constant page size (4kB).
		}
		\par{
			\noindent Three ingredients of external fragmentation:
			\parskip0pt\begin{enumerate}
				\item{out of order deallocation}
				\item{contiguity}
				\item{different page sizes}
			\end{enumerate}
		}
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				\node[draw, minimum height = 2cm, minimum width = 2cm] (address_1) {};
				\node[draw, minimum height = 2cm, minimum width = 2cm, right = -0.015 of address_1] (content_1) {};
				\node[draw, minimum height = 0.5cm, minimum width = 2cm, above = -0.015 of address_1] (address_2) {\footnotesize{$10$}};
				\node[draw, minimum height = 0.5cm, minimum width = 2cm, above = -0.015 of content_1] (content_2) {\footnotesize{$42$}};
				\node[draw, minimum height = 2cm, minimum width = 2cm, above = -0.015 of address_2] (address_3) {};
				\node[draw, minimum height = 2cm, minimum width = 2cm, above = -0.015 of content_2] (content_3) {};
				\node[above = 0 of address_3] {\footnotesize{address}};
				\node[above = 0 of content_3] {\footnotesize{content}};
 			\end{tikzpicture}
			\caption{TLB organisation}
			\label{fig:tlborg}
		\end{figure}
		\par{
			\noindent
			The operating system asks the TLB if it got address 10. But why in MMU/page table?
			\parskip0pt\begin{itemize}
				\item{cache hit: mapping in TLB.}
				\item{cache miss: mapping is looked up in page table $\Rightarrow$ slow and is stored in TLB after lookup.}
			\end{itemize}
		}
		\par{
			\noindent\underline{Fully-associative vs. direct-mapped cache:}
			\par{
				\noindent
				In fully-associative caches, when a request is made, the requested address is compared in a directory against all entries in the directory. If the requested address is found (\textit{directory hit}), the corresponding location in the cache is fetched and returned to the processor. Otherwise, a \textit{directory miss} occurs. \newline
				In direct-mapped caches, lower order line address bits are used to access the directory. Since multiple line addresses map into the same location in the cache directory, the upper line address bits must be compared with the directory address to ensure a directory hit. If a comparison is not valid, the result is a cache miss. The address given to the cache by the processor actually is subdivided into several pieces, each of which has a different role in accessing data.
			}
		}
	}
}
\par{
	\noindent\underline{On-demand paging:}
	\par{
		\noindent
		The straight-forward approach to implement a page table would be a gigantic array. But this could not be stored in memory for every process. The solution have (more or less) constant time and solves the memory problem: a tree structure where the root has children of mini page tables (see Figure~\ref{fig:2leveltree}).
	}
}
\par{
	\noindent\underline{Prefetching:}
	\par{
		\noindent
		Fetch neighbor entries in page table $\Rightarrow$ exploits the \textit{spatial locality} of code/applications.
	}
	\par{
		\noindent
		Spatial locality in caches: a whole cache line is loaded. Because of loops and contiguous allocated data structures (arrays, \ldots).
	}
	\par{
		\noindent
		Temporal locality: it is likely that a cached address is needed in the near future again. This is the reason caches work. There are almost no programs without this property because of loops, variable sharing and functions/methods.
	}
}
\par{
	\noindent
	We have perfect spatial isolation of processes. How do we establish interprocess communication? \newline
	Shared memory: different page table entries of different page tables map to the same memory.
}
\par{
	\noindent\underline{Process vs. Thread}
	\parskip0pt\begin{itemize}
		\item{
			Process:
			\parskip0pt\begin{itemize}
				\item{independent program counter}
				\item{independent registers}
				\item{independent virtual memory}
			\end{itemize}
		}
		\item{
			Thread:
			\parskip0pt\begin{itemize}
				\item{independent program counter}
				\item{independent registers}
				\item{independent stack, everything else is shared}
			\end{itemize}
		}
	\end{itemize}
	\par{
		\noindent
		Communication between threads is very fast because everything is shared except for the stack. This bad isolation is the reason that most multi-threaded applications are incorrect. The correctness proof of multi-threaded applications is very difficult.
	}
}
\par{
	\noindent 2 categories of page replacement algorithms:
	\parskip0pt\begin{enumerate}
		\item{frequency-based}
		\item{based on the point of time of the access}
	\end{enumerate}
}
\par{
	\noindent Thrashing:
	\par{
		\noindent
		All processes operating on more memory than physically available $\Rightarrow$ swap-out/-in all the time. 
	}
}
\par{
	\noindent\underline{Scheduling problem:}
	\par{
		\noindent
		$n$ processes \& all want to run. Fairness is important (no starvation of a single process), e.g. Round Robin, FIFO.
	}
	\par{
		\noindent
		Scheduler does the process switch. Processes switch their state between \textit{ready} and \textit{blocked} (in the simplest model on a single core system). Ready processes are in a running pool (unsorted set of ready processes, in general).
	}
	\par{
		\noindent
		Preemptive:
		\par{
			\noindent
			Triggered using hardware interrupts, otherwise the operating system would never get the CPU back from the process because the running process owns the CPU. Fundamental drawback: every code can be interrupted at any point of time $\Rightarrow$ correctness reasoning is difficult because of the complexity.
		}
	}
	\par{
		\noindent
		Cooperative:
		\par{
			\noindent
			Easier to implement. Fundamental drawback: if one process is not cooperative, the whole concept is broken.
		}
	}
}